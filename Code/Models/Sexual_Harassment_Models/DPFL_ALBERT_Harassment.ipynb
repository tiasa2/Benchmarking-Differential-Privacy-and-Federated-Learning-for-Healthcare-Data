{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DPFL_ALBERT_Harassment.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZFcT_ttb3cxp",
        "outputId": "c10acd03-48f9-4771-c1b7-766cd7df7658"
      },
      "source": [
        "!pip install transformers==3"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting transformers==3\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9c/35/1c3f6e62d81f5f0daff1384e6d5e6c5758682a8357ebc765ece2b9def62b/transformers-3.0.0-py3-none-any.whl (754kB)\n",
            "\u001b[K     |████████████████████████████████| 757kB 2.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers==3) (20.9)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers==3) (2019.12.20)\n",
            "Collecting sentencepiece\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f5/99/e0808cb947ba10f575839c43e8fafc9cc44e4a7a2c8f79c60db48220a577/sentencepiece-0.1.95-cp37-cp37m-manylinux2014_x86_64.whl (1.2MB)\n",
            "\u001b[K     |████████████████████████████████| 1.2MB 15.5MB/s \n",
            "\u001b[?25hCollecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/75/ee/67241dc87f266093c533a2d4d3d69438e57d7a90abb216fa076e7d475d4a/sacremoses-0.0.45-py3-none-any.whl (895kB)\n",
            "\u001b[K     |████████████████████████████████| 901kB 18.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from transformers==3) (1.19.5)\n",
            "Collecting tokenizers==0.8.0-rc4\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f7/82/0e82a95bd9db2b32569500cc1bb47aa7c4e0f57aa5e35cceba414096917b/tokenizers-0.8.0rc4-cp37-cp37m-manylinux1_x86_64.whl (3.0MB)\n",
            "\u001b[K     |████████████████████████████████| 3.0MB 23.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers==3) (2.23.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers==3) (4.41.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers==3) (3.0.12)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers==3) (2.4.7)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==3) (7.1.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==3) (1.15.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==3) (1.0.1)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==3) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==3) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==3) (2020.12.5)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==3) (1.24.3)\n",
            "Installing collected packages: sentencepiece, sacremoses, tokenizers, transformers\n",
            "Successfully installed sacremoses-0.0.45 sentencepiece-0.1.95 tokenizers-0.8.0rc4 transformers-3.0.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9MOR7QL-NqIW",
        "outputId": "0e0e155e-4d39-4f64-9a3e-bb897c99810b"
      },
      "source": [
        "!pip install opacus"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting opacus\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/68/c4/36f07b54413e607f07858d5b668379991948f0de9979185a895fee9c2208/opacus-0.13.0-py3-none-any.whl (102kB)\n",
            "\u001b[K     |████████████████████████████████| 102kB 2.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: torch>=1.3 in /usr/local/lib/python3.7/dist-packages (from opacus) (1.8.1+cu101)\n",
            "Requirement already satisfied: scipy>=1.2 in /usr/local/lib/python3.7/dist-packages (from opacus) (1.4.1)\n",
            "Requirement already satisfied: torchvision>=0.9 in /usr/local/lib/python3.7/dist-packages (from opacus) (0.9.1+cu101)\n",
            "Requirement already satisfied: numpy>=1.15 in /usr/local/lib/python3.7/dist-packages (from opacus) (1.19.5)\n",
            "Collecting requests>=2.25.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/29/c1/24814557f1d22c56d50280771a17307e6bf87b70727d975fd6b2ce6b014a/requests-2.25.1-py2.py3-none-any.whl (61kB)\n",
            "\u001b[K     |████████████████████████████████| 61kB 5.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.40 in /usr/local/lib/python3.7/dist-packages (from opacus) (4.41.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.3->opacus) (3.7.4.3)\n",
            "Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.7/dist-packages (from torchvision>=0.9->opacus) (7.1.2)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.25.1->opacus) (2020.12.5)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.25.1->opacus) (2.10)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.25.1->opacus) (1.24.3)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.25.1->opacus) (3.0.4)\n",
            "\u001b[31mERROR: google-colab 1.0.0 has requirement requests~=2.23.0, but you'll have requests 2.25.1 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: datascience 0.10.6 has requirement folium==0.2.1, but you'll have folium 0.8.3 which is incompatible.\u001b[0m\n",
            "Installing collected packages: requests, opacus\n",
            "  Found existing installation: requests 2.23.0\n",
            "    Uninstalling requests-2.23.0:\n",
            "      Successfully uninstalled requests-2.23.0\n",
            "Successfully installed opacus-0.13.0 requests-2.25.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mI_AcZbA20Ll"
      },
      "source": [
        "# Importing libraries\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import transformers\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "# Optimizer from hugging face transformers\n",
        "from transformers import AdamW\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report\n",
        "import transformers\n",
        "from transformers import AutoModel, AutoTokenizer\n",
        "import matplotlib.pyplot as plt\n",
        "from tqdm import tqdm\n",
        "import numpy as np\n",
        "import time\n",
        "import opacus\n",
        "from opacus import PrivacyEngine \n",
        "import copy\n",
        "import os\n",
        "import logging\n",
        "logging.basicConfig(level=logging.ERROR)"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VGLPc0Pw4a_W",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "95078844-998f-41f2-8eaf-fc9a8ef68f76"
      },
      "source": [
        "# Setting up GPU\n",
        "from torch import cuda\n",
        "device = 'cuda' if cuda.is_available() else 'cpu'\n",
        "print(device)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cuda\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "urJgZigehsge",
        "outputId": "94d4e267-e17c-4b47-986c-f74aad8a13a0"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 306
        },
        "id": "qm3GRXFa3Hbl",
        "outputId": "5786a775-6167-4cec-f047-b31da9f653c9"
      },
      "source": [
        "df = pd.read_csv('/content/drive/My Drive/Harassment_Cleaned_tweets.csv')\n",
        "df.head()"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>Key Word</th>\n",
              "      <th>Username</th>\n",
              "      <th>User_ID</th>\n",
              "      <th>Datetime</th>\n",
              "      <th>Favorite_count</th>\n",
              "      <th>Geo</th>\n",
              "      <th>Coordinates</th>\n",
              "      <th>Label</th>\n",
              "      <th>Text</th>\n",
              "      <th>Unnamed: 9</th>\n",
              "      <th>Unnamed: 10</th>\n",
              "      <th>Unnamed: 11</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>704</td>\n",
              "      <td>ass</td>\n",
              "      <td>DeborahParr</td>\n",
              "      <td>1.330000e+18</td>\n",
              "      <td>11-11-2020 06:56</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1</td>\n",
              "      <td>He’d have my phone wedged up his ass sideways.</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1915</td>\n",
              "      <td>boobies</td>\n",
              "      <td>MaxZorin85</td>\n",
              "      <td>1.330000e+18</td>\n",
              "      <td>11-11-2020 07:35</td>\n",
              "      <td>4</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>Yep 100% agree and the same with severine in s...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2856</td>\n",
              "      <td>eat pussy</td>\n",
              "      <td>PRISJ1_</td>\n",
              "      <td>1.330000e+18</td>\n",
              "      <td>11-11-2020 10:36</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1</td>\n",
              "      <td>Stop having sex with men that won’t eat your p...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2163</td>\n",
              "      <td>Breast Man</td>\n",
              "      <td>Teresamckenzy1</td>\n",
              "      <td>1.330000e+18</td>\n",
              "      <td>10-11-2020 20:52</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1</td>\n",
              "      <td>When you see a sad man, just give him breast t...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2852</td>\n",
              "      <td>eat pussy</td>\n",
              "      <td>sj__vazquez</td>\n",
              "      <td>1.330000e+18</td>\n",
              "      <td>11-11-2020 10:42</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1</td>\n",
              "      <td>We can't be together if you don't eat pussy</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Unnamed: 0    Key Word        Username  ...  Unnamed: 9 Unnamed: 10  Unnamed: 11\n",
              "0         704         ass     DeborahParr  ...         NaN         NaN          NaN\n",
              "1        1915     boobies      MaxZorin85  ...         NaN         NaN          NaN\n",
              "2        2856   eat pussy         PRISJ1_  ...         NaN         NaN          NaN\n",
              "3        2163  Breast Man  Teresamckenzy1  ...         NaN         NaN          NaN\n",
              "4        2852   eat pussy     sj__vazquez  ...         NaN         NaN          NaN\n",
              "\n",
              "[5 rows x 13 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1YhlneiEHzB8"
      },
      "source": [
        "##Partitioning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EGWafcsLH11y"
      },
      "source": [
        "###IID"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rPIyHBVTFifB"
      },
      "source": [
        "def iid_partition(dataset, clients):\n",
        "  \"\"\"\n",
        "  I.I.D paritioning of data over clients\n",
        "  Shuffle the data\n",
        "  Split it between clients\n",
        "  \n",
        "  params:\n",
        "    - dataset (torch.utils.Dataset): Dataset containing the MNIST Images\n",
        "    - clients (int): Number of Clients to split the data between\n",
        "\n",
        "  returns:\n",
        "    - Dictionary of image indexes for each client\n",
        "  \"\"\"\n",
        "\n",
        "  num_items_per_client = int(len(dataset)/clients)\n",
        "  client_dict = {}\n",
        "  image_idxs = [i for i in range(len(dataset))]\n",
        "\n",
        "  for i in range(clients):\n",
        "    client_dict[i] = set(np.random.choice(image_idxs, num_items_per_client, replace=False))\n",
        "    image_idxs = list(set(image_idxs) - client_dict[i])\n",
        "\n",
        "  return client_dict"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1hhMk0QAH4kr"
      },
      "source": [
        "###Non-IID"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8Vr78-GMFm9p"
      },
      "source": [
        "def non_iid_partition(dataset, clients, total_shards, shards_size, num_shards_per_client):\n",
        "  \"\"\"\n",
        "  non I.I.D parititioning of data over clients\n",
        "  Sort the data by the digit label\n",
        "  Divide the data into N shards of size S\n",
        "  Each of the clients will get X shards\n",
        "\n",
        "  params:\n",
        "    - dataset (torch.utils.Dataset): Dataset containing the MNIST Images\n",
        "    - clients (int): Number of Clients to split the data between\n",
        "    - total_shards (int): Number of shards to partition the data in\n",
        "    - shards_size (int): Size of each shard \n",
        "    - num_shards_per_client (int): Number of shards of size shards_size that each client receives\n",
        "\n",
        "  returns:\n",
        "    - Dictionary of image indexes for each client\n",
        "  \"\"\"\n",
        "  \n",
        "  shard_idxs = [i for i in range(total_shards)]\n",
        "  client_dict = {i: np.array([], dtype='int64') for i in range(clients)}\n",
        "  idxs = np.arange(len(dataset))\n",
        "  data_labels = dataset.get_labels()\n",
        "\n",
        "  # sort the labels\n",
        "  label_idxs = np.vstack((idxs, data_labels))\n",
        "  label_idxs = label_idxs[:, label_idxs[1,:].argsort()]\n",
        "  idxs = label_idxs[0,:]\n",
        "\n",
        "  # divide the data into total_shards of size shards_size\n",
        "  # assign num_shards_per_client to each client\n",
        "  for i in range(clients):\n",
        "    rand_set = set(np.random.choice(shard_idxs, num_shards_per_client, replace=False))\n",
        "    shard_idxs = list(set(shard_idxs) - rand_set)\n",
        "\n",
        "    for rand in rand_set:\n",
        "      client_dict[i] = np.concatenate((client_dict[i], idxs[rand*shards_size:(rand+1)*shards_size]), axis=0)\n",
        "  \n",
        "  return client_dict"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oBavKNvISnMS"
      },
      "source": [
        ""
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MbYgMVAcTWXC"
      },
      "source": [
        "# MAIN"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NvHtHWHsT5E3"
      },
      "source": [
        "## MODELS"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qp1ABLx_5jTK"
      },
      "source": [
        "# Importing BERT-base pretrained model\n",
        "bert = AutoModel.from_pretrained('albert-base-v2')\n",
        "# Load the BERT tokenizer\n",
        "tokenizer = AutoTokenizer.from_pretrained('albert-base-v2')"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mcAr1VZ_vX7B"
      },
      "source": [
        "# Model Architecture\n",
        "\n",
        "class BERT_Arch(nn.Module):\n",
        "\n",
        "    def __init__(self, bert):\n",
        "      \n",
        "      super(BERT_Arch, self).__init__()\n",
        "\n",
        "      self.bert = bert \n",
        "      \n",
        "      # Dropout layer\n",
        "      self.dropout = nn.Dropout(0.1)\n",
        "      \n",
        "      # Relu activation function\n",
        "      self.relu =  nn.ReLU()\n",
        "\n",
        "      # Dense layer 1\n",
        "      self.fc1 = nn.Linear(768,512)\n",
        "      \n",
        "      # Dense layer 2 (Output layer)\n",
        "      self.fc2 = nn.Linear(512,2)\n",
        "\n",
        "      # Softmax activation function\n",
        "      self.softmax = nn.LogSoftmax(dim=1)\n",
        "\n",
        "    # Define the forward pass\n",
        "    def forward(self, sent_id, mask):\n",
        "\n",
        "      # Pass the inputs to the model  \n",
        "      _, cls_hs = self.bert(sent_id, attention_mask=mask)\n",
        "      \n",
        "      x = self.fc1(cls_hs)\n",
        "\n",
        "      x = self.relu(x)\n",
        "\n",
        "      x = self.dropout(x)\n",
        "\n",
        "      # Output layer\n",
        "      x = self.fc2(x)\n",
        "      \n",
        "      # Apply softmax activation\n",
        "      x = self.softmax(x)\n",
        "\n",
        "      return x"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4oDoBoYdvay8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "783d021b-9222-4bb7-ea19-1cc6fc9ffe93"
      },
      "source": [
        "# Pass the pre-trained BERT to our define architecture\n",
        "model = BERT_Arch(bert)\n",
        "\n",
        "# Push the model to GPU\n",
        "model = model.to(device)\n",
        "model"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BERT_Arch(\n",
              "  (bert): AlbertModel(\n",
              "    (embeddings): AlbertEmbeddings(\n",
              "      (word_embeddings): Embedding(30000, 128, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 128)\n",
              "      (token_type_embeddings): Embedding(2, 128)\n",
              "      (LayerNorm): LayerNorm((128,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0, inplace=False)\n",
              "    )\n",
              "    (encoder): AlbertTransformer(\n",
              "      (embedding_hidden_mapping_in): Linear(in_features=128, out_features=768, bias=True)\n",
              "      (albert_layer_groups): ModuleList(\n",
              "        (0): AlbertLayerGroup(\n",
              "          (albert_layers): ModuleList(\n",
              "            (0): AlbertLayer(\n",
              "              (full_layer_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (attention): AlbertAttention(\n",
              "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (dropout): Dropout(p=0, inplace=False)\n",
              "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              )\n",
              "              (ffn): Linear(in_features=768, out_features=3072, bias=True)\n",
              "              (ffn_output): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): Linear(in_features=768, out_features=768, bias=True)\n",
              "    (pooler_activation): Tanh()\n",
              "  )\n",
              "  (dropout): Dropout(p=0.1, inplace=False)\n",
              "  (relu): ReLU()\n",
              "  (fc1): Linear(in_features=768, out_features=512, bias=True)\n",
              "  (fc2): Linear(in_features=512, out_features=2, bias=True)\n",
              "  (softmax): LogSoftmax(dim=1)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SJWgqL5dOMns",
        "outputId": "0df9cb15-5844-4e17-ebc3-7bf6d11db7c8"
      },
      "source": [
        "trainable_layers = [model.fc1, model.fc2]\n",
        "total_params = 0\n",
        "trainable_params = 0\n",
        "\n",
        "for p in model.parameters():\n",
        "        p.requires_grad = False\n",
        "        total_params += p.numel()\n",
        "\n",
        "for layer in trainable_layers:\n",
        "    for p in layer.parameters():\n",
        "        p.requires_grad = True\n",
        "        trainable_params += p.numel()\n",
        "\n",
        "print(f\"Total parameters count: {total_params}\") # ~125M\n",
        "print(f\"Trainable parameters count: {trainable_params}\") # ~0.5M"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total parameters count: 12078338\n",
            "Trainable parameters count: 394754\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eJYVU02b4DjQ"
      },
      "source": [
        "#Initialization\n",
        "MAX_LEN = 256\n",
        "TRAIN_BATCH_SIZE = 8\n",
        "VALID_BATCH_SIZE = 2\n",
        "#EPOCHS = 10\n",
        "LEARNING_RATE = 1e-05\n",
        "#tokenizer = RobertaTokenizer.from_pretrained('roberta-base', truncation=True, do_lower_case=True)"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oOV8C2S54FXw"
      },
      "source": [
        "#The class is defined to accept the Dataframe as input and generate tokenized output that is used by the DistilBERT model for training.\n",
        "#The tokenizer uses the encode_plus method to perform tokenization and generate the necessary outputs, namely: ids, attention_mask\n",
        "class Triage(Dataset):\n",
        "    def __init__(self, dataframe, tokenizer, max_len):\n",
        "        self.len = len(dataframe)\n",
        "        self.data = dataframe\n",
        "        self.tokenizer = tokenizer\n",
        "        self.max_len = max_len\n",
        "\n",
        "    def get_labels(self):\n",
        "        l = []\n",
        "        for i in range(self.len):\n",
        "          title = str(self.data.Text[i])\n",
        "          title = \" \".join(title.split())\n",
        "          inputs = self.tokenizer.encode_plus(\n",
        "              title,\n",
        "              None,\n",
        "              add_special_tokens=True,\n",
        "              max_length=self.max_len,\n",
        "              padding='max_length',\n",
        "              return_token_type_ids=True,\n",
        "              truncation=True\n",
        "          )\n",
        "\n",
        "          l.append(self.data.Label[i])\n",
        "\n",
        "        return l     \n",
        "\n",
        "        \n",
        "    def __getitem__(self, index):\n",
        "        title = str(self.data.Text[index])\n",
        "        title = \" \".join(title.split())\n",
        "        inputs = self.tokenizer.encode_plus(\n",
        "            title,\n",
        "            None,\n",
        "            add_special_tokens=True,\n",
        "            max_length=self.max_len,\n",
        "            padding='max_length',\n",
        "            return_token_type_ids=True,\n",
        "            truncation=True\n",
        "        )\n",
        "        ids = inputs['input_ids']\n",
        "        mask = inputs['attention_mask']\n",
        "\n",
        "        return {\n",
        "            'ids': torch.tensor(ids, dtype=torch.long),\n",
        "            'mask': torch.tensor(mask, dtype=torch.long),\n",
        "            'targets': torch.tensor(self.data.Label[index], dtype=torch.long)\n",
        "        } \n",
        "    \n",
        "    def __len__(self):\n",
        "        return self.len"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_eIAvHupTiBO"
      },
      "source": [
        "class CustomDataset(Dataset):\n",
        "  def __init__(self, dataset, tokenizer, max_len, idxs):\n",
        "      self.data = dataset\n",
        "      self.idxs = list(idxs)\n",
        "      self.tokenizer = tokenizer\n",
        "      self.max_len = max_len\n",
        "      \n",
        "  # def __init__(self, dataset, idxs):\n",
        "  #     self.dataset = dataset\n",
        "  #     self.idxs = list(idxs)\n",
        "\n",
        "  def __len__(self):\n",
        "      return len(self.idxs)\n",
        "\n",
        "  def __getitem__(self, index):\n",
        "      title = str(self.data.Text[index])\n",
        "      title = \" \".join(title.split())\n",
        "      inputs = self.tokenizer.encode_plus(\n",
        "          title,\n",
        "          None,\n",
        "          add_special_tokens=True,\n",
        "          max_length=self.max_len,\n",
        "          padding='max_length',\n",
        "          return_token_type_ids=True,\n",
        "          truncation=True\n",
        "      )\n",
        "      ids = inputs['input_ids']\n",
        "      mask = inputs['attention_mask']\n",
        "\n",
        "      return {\n",
        "          'ids': torch.tensor(ids, dtype=torch.long),\n",
        "          'mask': torch.tensor(mask, dtype=torch.long),\n",
        "          'targets': torch.tensor(self.data.Label[index], dtype=torch.long)\n",
        "      } \n",
        "\n",
        "class ClientUpdate(object):\n",
        "  def __init__(self, dataset, model, tokenizer, loss_function, optimizer, idxs, epochs, MAX_LEN=256):\n",
        "    self.train_loader = DataLoader(CustomDataset(dataset, tokenizer, MAX_LEN, idxs), batch_size=8, shuffle=True)\n",
        "    self.model = model\n",
        "    self.dataset = dataset\n",
        "    self.loss_function = loss_function\n",
        "    self.optimizer = optimizer\n",
        "    self.epochs = epochs\n",
        "\n",
        "  # Function to calcuate the accuracy of the model\n",
        "\n",
        "  def calcuate_accu(self, big_idx, targets):\n",
        "    n_correct = (big_idx==targets).sum().item()\n",
        "    return n_correct\n",
        "\n",
        "  def train(self):\n",
        "\n",
        "    epochloss, epochacc = [], []\n",
        "\n",
        "    for epoch in range(1, self.epochs+1):\n",
        "      tr_loss = 0\n",
        "      n_correct = 0\n",
        "      nb_tr_steps = 0\n",
        "      nb_tr_examples = 0\n",
        "      losses = []\n",
        "      model.train()\n",
        "      for _,data in tqdm(enumerate(training_loader, 0)):\n",
        "          ids = data['ids'].to(device, dtype = torch.long)\n",
        "          mask = data['mask'].to(device, dtype = torch.long)\n",
        "          #token_type_ids = data['token_type_ids'].to(device, dtype = torch.long)\n",
        "          targets = data['targets'].to(device, dtype = torch.long)\n",
        "\n",
        "          outputs = model(ids, mask)\n",
        "          loss = loss_function(outputs, targets)\n",
        "          tr_loss += loss.item()\n",
        "          big_val, big_idx = torch.max(outputs.data, dim=1)\n",
        "          n_correct += self.calcuate_accu(big_idx, targets)\n",
        "\n",
        "          nb_tr_steps += 1\n",
        "          nb_tr_examples+=targets.size(0)\n",
        "          \n",
        "          if _%2000==0:\n",
        "              loss_step = tr_loss/nb_tr_steps\n",
        "              accu_step = (n_correct*100)/nb_tr_examples \n",
        "              print(f\"Training Loss per 5000 steps: {loss_step}\")\n",
        "              print(f\"Training Accuracy per 5000 steps: {accu_step}\")\n",
        "\n",
        "          self.optimizer.zero_grad()\n",
        "          loss.backward()\n",
        "          losses.append(loss.item())\n",
        "          # # When using GPU\n",
        "          if (_ + 1) % 2000 == 0 or _ == len(training_loader) - 1:\n",
        "              self.optimizer.step()\n",
        "          else:\n",
        "              self.optimizer.virtual_step()\n",
        "\n",
        "          if _ > 0 and _ % 2000 == 0:\n",
        "                train_loss = np.mean(losses)\n",
        "                eps, alpha = self.optimizer.privacy_engine.get_privacy_spent(DELTA)\n",
        "\n",
        "                eval_accuracy,eval_loss = valid(model, testing_loader)\n",
        "\n",
        "                print(\n",
        "                    f\"Epoch: {epoch} | \"\n",
        "                    f\"Step: {_} | \"\n",
        "                    f\"Train loss: {train_loss:.3f} | \"\n",
        "                    f\"Eval loss: {eval_loss:.3f} | \"\n",
        "                    f\"Eval accuracy: {eval_accuracy:.3f} | \"\n",
        "                    f\"ɛ: {eps:.2f} (α: {alpha})\"\n",
        "                )\n",
        "\n",
        "          \n",
        "      print(f'The Total Accuracy for Epoch {epoch}: {(n_correct*100)/nb_tr_examples}')\n",
        "      epoch_loss = tr_loss/nb_tr_steps\n",
        "      epoch_accu = (n_correct*100)/nb_tr_examples\n",
        "      print(f\"Training Loss Epoch: {epoch_loss}\")\n",
        "      print(f\"Training Accuracy Epoch: {epoch_accu}\")\n",
        "      epochacc.append(epoch_accu)\n",
        "      epochloss.append(epoch_loss)\n",
        "\n",
        "\n",
        "    return model.state_dict(), epochacc[-1], epochloss[-1]"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NC6o9ggzVCNW"
      },
      "source": [
        "def training(model, rounds, ds, data_dict, loss_function, lr, C, K, E, plt_color):\n",
        "  \"\"\"\n",
        "  Function implements the Federated Averaging Algorithm from the FedAvg paper.\n",
        "  Specifically, this function is used for the server side training and weight update\n",
        "\n",
        "  Params:\n",
        "    - model:           PyTorch model to train\n",
        "    - rounds:          Number of communication rounds for the client update\n",
        "    - batch_size:      Batch size for client update training\n",
        "    - lr:              Learning rate used for client update training\n",
        "    - ds:              Dataset used for training\n",
        "    - data_dict:       Type of data partition used for training (IID or non-IID)\n",
        "    - C:               Fraction of clients randomly chosen to perform computation on each round\n",
        "    - K:               Total number of clients\n",
        "    - E:               Number of training passes each client makes over its local dataset per round\n",
        "    - tb_writer_name:  Directory name to save the tensorboard logs\n",
        "  Returns:\n",
        "    - model:           Trained model on the server\n",
        "  \"\"\"\n",
        "\n",
        "  # global model weights\n",
        "  global_weights = model.state_dict()\n",
        "\n",
        "  # training loss\n",
        "  train_loss,train_acc = [], []\n",
        "  \n",
        "  optimizer = torch.optim.AdamW(params =  model.parameters(), lr=lr)\n",
        "  \n",
        "  # measure time\n",
        "  start = time.time()\n",
        "\n",
        "  LOGGING_INTERVAL = 100 # once every how many steps we run evaluation cycle and report metrics\n",
        "  EPSILON = 0.5\n",
        "  DELTA = 1 / len(training_set) # Parameter for privacy accounting. Probability of not achieving privacy guarantees\n",
        "\n",
        "  SAMPLE_RATE = 8/len(ds)\n",
        "  MAX_GRAD_NORM = 0.1\n",
        "  VIRTUAL_BATCH_SIZE = 32\n",
        "  assert VIRTUAL_BATCH_SIZE % 8 == 0 # VIRTUAL_BATCH_SIZE should be divisible by BATCH_SIZE\n",
        "  N_ACCUMULATION_STEPS = int(VIRTUAL_BATCH_SIZE / 8)\n",
        "\n",
        "  privacy_engine = PrivacyEngine(\n",
        "      module=model,\n",
        "      sample_rate=SAMPLE_RATE * N_ACCUMULATION_STEPS,\n",
        "      target_delta = DELTA,\n",
        "      target_epsilon = EPSILON, \n",
        "      epochs = E,\n",
        "      max_grad_norm=MAX_GRAD_NORM,\n",
        "  )\n",
        "\n",
        "  privacy_engine.attach(optimizer)\n",
        "    \n",
        "\n",
        "  for curr_round in range(1, rounds+1):\n",
        "    w, local_loss,local_acc = [], [], []\n",
        "\n",
        "    m = max(int(C*K), 1)\n",
        "    \n",
        "    S_t = np.random.choice(range(K), m, replace=False)\n",
        "    for k in S_t:\n",
        "      local_update = ClientUpdate(dataset=ds, model=model, tokenizer=tokenizer, loss_function=loss_function, \\\n",
        "                                  optimizer=optimizer, epochs=E, idxs=data_dict[k])\n",
        "      weights, acc, loss = local_update.train()\n",
        "\n",
        "      w.append(copy.deepcopy(weights))\n",
        "      local_loss.append(copy.deepcopy(loss))\n",
        "      local_acc.append(copy.deepcopy(acc))\n",
        "\n",
        "    # updating the global weights\n",
        "    weights_avg = copy.deepcopy(w[0])\n",
        "    for k in weights_avg.keys():\n",
        "      for i in range(1, len(w)):\n",
        "        weights_avg[k] += w[i][k]\n",
        "\n",
        "      weights_avg[k] = torch.div(weights_avg[k], len(w))\n",
        "\n",
        "    global_weights = weights_avg\n",
        "\n",
        "    # move the updated weights to our model state dict\n",
        "    model.load_state_dict(global_weights)\n",
        "\n",
        "    # loss\n",
        "    loss_avg = sum(local_loss) / len(local_loss)\n",
        "    acc_avg = sum(local_acc) / len(local_acc)\n",
        "    print('Round: {}... \\tAverage Loss: {}'.format(curr_round, round(loss_avg, 3)))\n",
        "    print('Round: {}... \\tAverage Accuracy: {}'.format(curr_round, round(acc_avg, 3)))\n",
        "    train_loss.append(loss_avg)\n",
        "    train_acc.append(acc_avg)\n",
        "\n",
        "  end = time.time()\n",
        "  \n",
        "  fig, ax = plt.subplots()\n",
        "  x_axis = np.arange(1, rounds+1)\n",
        "  # y_axis = np.array(train_loss)\n",
        "  # ax.plot(x_axis, y_axis, 'tab:'+plt_color)\n",
        "\n",
        "  # ax.set(xlabel='Number of Rounds', ylabel='Train Loss',\n",
        "  #      title=\"Training Loss\")\n",
        "  \n",
        "  y_axis = np.array(train_acc)\n",
        "  ax.plot(x_axis, y_axis, 'tab:'+plt_color)\n",
        "\n",
        "  ax.set(xlabel='Number of Rounds', ylabel='Train Accuracy',\n",
        "       title=\"Training Accuracy vs. Global rounds\")\n",
        "  ax.grid()\n",
        "  #fig.savefig(plt_title+'.jpg', format='jpg')\n",
        "  print(\"Training Done!\")\n",
        "  print(\"Total time taken to Train: {}\".format(end-start))\n",
        "  \n",
        "  return model, train_acc"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dfPQekmI4JCv",
        "outputId": "43d378ca-16e9-45f9-93e8-099295b86b9c"
      },
      "source": [
        "# Creating the dataset and dataloader for the neural network\n",
        "\n",
        "train_size = 0.8\n",
        "train_dataset=df.sample(frac=train_size,random_state=200)\n",
        "test_dataset=df.drop(train_dataset.index).reset_index(drop=True)\n",
        "train_dataset = train_dataset.reset_index(drop=True)\n",
        "\n",
        "\n",
        "print(\"FULL Dataset: {}\".format(df.shape))\n",
        "print(\"TRAIN Dataset: {}\".format(train_dataset.shape))\n",
        "print(\"TEST Dataset: {}\".format(test_dataset.shape))\n",
        "\n",
        "training_set = Triage(train_dataset, tokenizer, MAX_LEN)\n",
        "testing_set = Triage(test_dataset, tokenizer, MAX_LEN)"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "FULL Dataset: (3604, 13)\n",
            "TRAIN Dataset: (2883, 13)\n",
            "TEST Dataset: (721, 13)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4DIl0v0P4Lss"
      },
      "source": [
        "train_params = {'batch_size': TRAIN_BATCH_SIZE,\n",
        "                'shuffle': True,\n",
        "                'num_workers': 0\n",
        "                }\n",
        "\n",
        "test_params = {'batch_size': VALID_BATCH_SIZE,\n",
        "                'shuffle': True,\n",
        "                'num_workers': 0\n",
        "                }\n",
        "\n",
        "training_loader = DataLoader(training_set, **train_params)\n",
        "testing_loader = DataLoader(testing_set, **test_params)"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zW4QTZ4Xtb9e",
        "outputId": "5aa009d1-4b6b-4468-dd4c-97ee1f6cec3e"
      },
      "source": [
        "# number of training rounds\n",
        "rounds = 3\n",
        "# client fraction\n",
        "C = 0.5\n",
        "# number of clients\n",
        "K = 10\n",
        "# number of training passes on local dataset for each round\n",
        "E = 3\n",
        "# batch size\n",
        "batch_size = 10\n",
        "# learning Rate\n",
        "lr=1e-05\n",
        "# dict containing different type of data partition\n",
        "data_dict = iid_partition(training_set, 10)\n",
        "d = {}\n",
        "loss_function = torch.nn.CrossEntropyLoss()\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "  model.cuda()\n",
        "\n",
        "bert_iid_trained, train_acc = training(model, rounds, train_dataset, data_dict, loss_function, lr, C, K, E, \"orange\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:523: UserWarning: A ``sample_rate`` has been provided.Thus, the provided ``batch_size``and ``sample_size`` will be ignored.\n",
            "  \"A ``sample_rate`` has been provided.\"\n",
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:195: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_rng`` turned on.\n",
            "  \"Secure RNG turned off. This is perfectly fine for experimentation as it allows \"\n",
            "0it [00:00, ?it/s]/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py:795: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
            "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n",
            "1it [00:00,  1.78it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training Loss per 5000 steps: 0.6657230854034424\n",
            "Training Accuracy per 5000 steps: 62.5\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "309it [01:31,  3.40it/s]"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TSimnCo6Sg1t"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c6TxASf-2aK5"
      },
      "source": [
        "def calcuate_accuracy(big_idx, targets):\n",
        "  n_correct = (big_idx==targets).sum().item()\n",
        "  return n_correct"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KfihyQ6Btb7I"
      },
      "source": [
        "#Testing the trained model\n",
        "\n",
        "def valid(model, testing_loader, loss_function):\n",
        "    model.eval()\n",
        "    n_correct = 0; n_wrong = 0; total = 0; tr_loss=0; nb_tr_steps=0; nb_tr_examples=0\n",
        "    with torch.no_grad():\n",
        "        for _, data in tqdm(enumerate(testing_loader, 0)):\n",
        "            ids = data['ids'].to(device, dtype = torch.long)\n",
        "            mask = data['mask'].to(device, dtype = torch.long)\n",
        "            #token_type_ids = data['token_type_ids'].to(device, dtype=torch.long)\n",
        "            targets = data['targets'].to(device, dtype = torch.long)\n",
        "            outputs = model(ids, mask)\n",
        "            loss = loss_function(outputs, targets)\n",
        "            tr_loss += loss.item()\n",
        "            big_val, big_idx = torch.max(outputs.data, dim=1)\n",
        "            n_correct += calcuate_accuracy(big_idx, targets)\n",
        "\n",
        "            nb_tr_steps += 1\n",
        "            nb_tr_examples+=targets.size(0)\n",
        "            \n",
        "            if _%5000==0:\n",
        "                loss_step = tr_loss/nb_tr_steps\n",
        "                accu_step = (n_correct*100)/nb_tr_examples\n",
        "                print(f\"Validation Loss per 100 steps: {loss_step}\")\n",
        "                print(f\"Validation Accuracy per 100 steps: {accu_step}\")\n",
        "    epoch_loss = tr_loss/nb_tr_steps\n",
        "    epoch_accu = (n_correct*100)/nb_tr_examples\n",
        "    print(f\"Validation Loss Epoch: {epoch_loss}\")\n",
        "    print(f\"Validation Accuracy Epoch: {epoch_accu}\")\n",
        "    \n",
        "    return epoch_accu\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K7PrSwkDrK-c"
      },
      "source": [
        "import pickle"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DEWigxtmVCKn"
      },
      "source": [
        "print('This is the validation section to print the accuracy and see how it performs')\n",
        "print('Here we are leveraging on the dataloader crearted for the validation dataset, the approcah is using more of pytorch')\n",
        "\n",
        "acc = valid(bert_iid_trained, testing_loader, loss_function)\n",
        "print(\"Accuracy on test data = %0.2f%%\" % acc)\n",
        "\n",
        "d['train_acc'] = train_acc\n",
        "d['test_acc'] = acc\n",
        "\n",
        "\n",
        "with open(f'/content/drive/My Drive/Albert/Sexual_Harassment/DPFLALBERT_Harassment_eps0_5.pkl', 'wb') as file:\n",
        "  pickle.dump(d, file)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "XAc_W8Yn0w8g",
        "outputId": "f1a4dc33-b5b5-4be2-dd67-5c9f2f823d63"
      },
      "source": [
        "# number of training rounds\n",
        "rounds = 3\n",
        "# client fraction\n",
        "C = 0.5\n",
        "# number of clients\n",
        "K = 10\n",
        "# number of training passes on local dataset for each round\n",
        "E = 3\n",
        "# batch size\n",
        "batch_size = 10\n",
        "# learning Rate\n",
        "lr=1e-05\n",
        "# dict containing different type of data partition\n",
        "data_dict = non_iid_partition(training_set, 10, 240, 10, 10)\n",
        "#iid_partition(training_set, 10)\n",
        "d={}\n",
        "loss_function = torch.nn.CrossEntropyLoss()\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "  model.cuda()\n",
        "\n",
        "bert_non_iid_trained, train_acc = training(model, rounds, train_dataset, data_dict, loss_function, lr, C, K, E, \"orange\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:523: UserWarning: A ``sample_rate`` has been provided.Thus, the provided ``batch_size``and ``sample_size`` will be ignored.\n",
            "  \"A ``sample_rate`` has been provided.\"\n",
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:195: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_rng`` turned on.\n",
            "  \"Secure RNG turned off. This is perfectly fine for experimentation as it allows \"\n",
            "0it [00:00, ?it/s]/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py:795: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
            "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n",
            "1it [00:00,  2.78it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training Loss per 5000 steps: 0.7259150147438049\n",
            "Training Accuracy per 5000 steps: 37.5\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "310it [01:25,  3.64it/s]\n",
            "0it [00:00, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "The Total Accuracy for Epoch 1: 31.005248284214776\n",
            "Training Loss Epoch: 0.7368929407288951\n",
            "Training Accuracy Epoch: 31.005248284214776\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r1it [00:00,  3.71it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training Loss per 5000 steps: 0.778868556022644\n",
            "Training Accuracy per 5000 steps: 12.5\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "310it [01:25,  3.63it/s]\n",
            "0it [00:00, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "The Total Accuracy for Epoch 2: 30.11707710940654\n",
            "Training Loss Epoch: 0.7374415701435458\n",
            "Training Accuracy Epoch: 30.11707710940654\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r1it [00:00,  3.69it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training Loss per 5000 steps: 0.7232372760772705\n",
            "Training Accuracy per 5000 steps: 50.0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "310it [01:25,  3.64it/s]\n",
            "0it [00:00, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "The Total Accuracy for Epoch 3: 30.15744852644328\n",
            "Training Loss Epoch: 0.7371466521293887\n",
            "Training Accuracy Epoch: 30.15744852644328\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r1it [00:00,  3.61it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training Loss per 5000 steps: 0.6542865037918091\n",
            "Training Accuracy per 5000 steps: 50.0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "310it [01:25,  3.63it/s]\n",
            "0it [00:00, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "The Total Accuracy for Epoch 1: 29.632620104965685\n",
            "Training Loss Epoch: 0.7386578481043539\n",
            "Training Accuracy Epoch: 29.632620104965685\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r1it [00:00,  3.70it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training Loss per 5000 steps: 0.7528366446495056\n",
            "Training Accuracy per 5000 steps: 25.0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "310it [01:25,  3.63it/s]\n",
            "0it [00:00, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "The Total Accuracy for Epoch 2: 30.278562777553493\n",
            "Training Loss Epoch: 0.7371949103570754\n",
            "Training Accuracy Epoch: 30.278562777553493\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r1it [00:00,  3.65it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training Loss per 5000 steps: 0.7289296388626099\n",
            "Training Accuracy per 5000 steps: 37.5\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "310it [01:25,  3.63it/s]\n",
            "0it [00:00, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "The Total Accuracy for Epoch 3: 29.30964876867178\n",
            "Training Loss Epoch: 0.7379899640237132\n",
            "Training Accuracy Epoch: 29.30964876867178\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r1it [00:00,  3.66it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training Loss per 5000 steps: 0.7846379280090332\n",
            "Training Accuracy per 5000 steps: 0.0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "310it [01:25,  3.64it/s]\n",
            "0it [00:00, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "The Total Accuracy for Epoch 1: 29.55187727089221\n",
            "Training Loss Epoch: 0.7381296703892369\n",
            "Training Accuracy Epoch: 29.55187727089221\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r1it [00:00,  3.75it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training Loss per 5000 steps: 0.7586052417755127\n",
            "Training Accuracy per 5000 steps: 25.0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "310it [01:25,  3.64it/s]\n",
            "0it [00:00, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "The Total Accuracy for Epoch 2: 30.036334275333065\n",
            "Training Loss Epoch: 0.736965948343277\n",
            "Training Accuracy Epoch: 30.036334275333065\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r1it [00:00,  3.63it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training Loss per 5000 steps: 0.7768765687942505\n",
            "Training Accuracy per 5000 steps: 25.0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "310it [01:25,  3.63it/s]\n",
            "0it [00:00, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "The Total Accuracy for Epoch 3: 31.005248284214776\n",
            "Training Loss Epoch: 0.7363879261478301\n",
            "Training Accuracy Epoch: 31.005248284214776\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r1it [00:00,  3.64it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training Loss per 5000 steps: 0.7578685283660889\n",
            "Training Accuracy per 5000 steps: 25.0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "310it [01:25,  3.64it/s]\n",
            "0it [00:00, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "The Total Accuracy for Epoch 1: 30.197819943480017\n",
            "Training Loss Epoch: 0.7379618158263545\n",
            "Training Accuracy Epoch: 30.197819943480017\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r1it [00:00,  3.71it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training Loss per 5000 steps: 0.7267207503318787\n",
            "Training Accuracy per 5000 steps: 25.0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "310it [01:25,  3.63it/s]\n",
            "0it [00:00, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "The Total Accuracy for Epoch 2: 30.76301978199435\n",
            "Training Loss Epoch: 0.7364211236276934\n",
            "Training Accuracy Epoch: 30.76301978199435\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r1it [00:00,  3.71it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training Loss per 5000 steps: 0.7749479413032532\n",
            "Training Accuracy per 5000 steps: 12.5\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "310it [01:24,  3.65it/s]\n",
            "0it [00:00, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "The Total Accuracy for Epoch 3: 30.803391199031086\n",
            "Training Loss Epoch: 0.7369315751137272\n",
            "Training Accuracy Epoch: 30.803391199031086\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r1it [00:00,  3.76it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training Loss per 5000 steps: 0.714235782623291\n",
            "Training Accuracy per 5000 steps: 50.0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "310it [01:25,  3.63it/s]\n",
            "0it [00:00, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "The Total Accuracy for Epoch 1: 31.166733952361728\n",
            "Training Loss Epoch: 0.7368133817949603\n",
            "Training Accuracy Epoch: 31.166733952361728\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r1it [00:00,  3.77it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training Loss per 5000 steps: 0.7634075880050659\n",
            "Training Accuracy per 5000 steps: 12.5\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "310it [01:25,  3.64it/s]\n",
            "0it [00:00, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "The Total Accuracy for Epoch 2: 30.238191360516755\n",
            "Training Loss Epoch: 0.7385817050933838\n",
            "Training Accuracy Epoch: 30.238191360516755\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r1it [00:00,  3.73it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training Loss per 5000 steps: 0.7029312252998352\n",
            "Training Accuracy per 5000 steps: 50.0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "310it [01:25,  3.64it/s]\n",
            "0it [00:00, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "The Total Accuracy for Epoch 3: 30.15744852644328\n",
            "Training Loss Epoch: 0.7362542679232936\n",
            "Training Accuracy Epoch: 30.15744852644328\n",
            "Round: 1... \tAverage Loss: 0.737\n",
            "Round: 1... \tAverage Accuracy: 30.287\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r1it [00:00,  3.76it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training Loss per 5000 steps: 0.7336524724960327\n",
            "Training Accuracy per 5000 steps: 37.5\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "310it [01:25,  3.64it/s]\n",
            "0it [00:00, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "The Total Accuracy for Epoch 1: 30.31893419459023\n",
            "Training Loss Epoch: 0.7362084496405816\n",
            "Training Accuracy Epoch: 30.31893419459023\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r1it [00:00,  3.78it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training Loss per 5000 steps: 0.7418780326843262\n",
            "Training Accuracy per 5000 steps: 25.0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "310it [01:25,  3.64it/s]\n",
            "0it [00:00, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "The Total Accuracy for Epoch 2: 31.166733952361728\n",
            "Training Loss Epoch: 0.737465549092139\n",
            "Training Accuracy Epoch: 31.166733952361728\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r1it [00:00,  3.70it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training Loss per 5000 steps: 0.6980931162834167\n",
            "Training Accuracy per 5000 steps: 37.5\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "310it [01:25,  3.64it/s]\n",
            "0it [00:00, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "The Total Accuracy for Epoch 3: 30.15744852644328\n",
            "Training Loss Epoch: 0.7367040634155273\n",
            "Training Accuracy Epoch: 30.15744852644328\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r1it [00:00,  3.73it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training Loss per 5000 steps: 0.7317876815795898\n",
            "Training Accuracy per 5000 steps: 25.0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "310it [01:25,  3.64it/s]\n",
            "0it [00:00, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "The Total Accuracy for Epoch 1: 29.7537343560759\n",
            "Training Loss Epoch: 0.7361845377952821\n",
            "Training Accuracy Epoch: 29.7537343560759\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r1it [00:00,  3.80it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training Loss per 5000 steps: 0.7050455808639526\n",
            "Training Accuracy per 5000 steps: 50.0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "310it [01:25,  3.64it/s]\n",
            "0it [00:00, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "The Total Accuracy for Epoch 2: 30.440048445700445\n",
            "Training Loss Epoch: 0.7377736241586746\n",
            "Training Accuracy Epoch: 30.440048445700445\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r1it [00:00,  3.75it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training Loss per 5000 steps: 0.7665836811065674\n",
            "Training Accuracy per 5000 steps: 12.5\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "310it [01:25,  3.64it/s]\n",
            "0it [00:00, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "The Total Accuracy for Epoch 3: 31.207105369398466\n",
            "Training Loss Epoch: 0.7365033449665193\n",
            "Training Accuracy Epoch: 31.207105369398466\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r1it [00:00,  3.72it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training Loss per 5000 steps: 0.751865029335022\n",
            "Training Accuracy per 5000 steps: 37.5\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "310it [01:25,  3.63it/s]\n",
            "0it [00:00, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "The Total Accuracy for Epoch 1: 30.682276947920872\n",
            "Training Loss Epoch: 0.735865371265719\n",
            "Training Accuracy Epoch: 30.682276947920872\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r1it [00:00,  3.68it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training Loss per 5000 steps: 0.783675491809845\n",
            "Training Accuracy per 5000 steps: 12.5\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "310it [01:25,  3.64it/s]\n",
            "0it [00:00, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "The Total Accuracy for Epoch 2: 30.197819943480017\n",
            "Training Loss Epoch: 0.7369487018354477\n",
            "Training Accuracy Epoch: 30.197819943480017\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r1it [00:00,  3.80it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training Loss per 5000 steps: 0.7362558841705322\n",
            "Training Accuracy per 5000 steps: 37.5\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "310it [01:25,  3.64it/s]\n",
            "0it [00:00, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "The Total Accuracy for Epoch 3: 29.874848607186113\n",
            "Training Loss Epoch: 0.7380309145296774\n",
            "Training Accuracy Epoch: 29.874848607186113\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r1it [00:00,  3.76it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training Loss per 5000 steps: 0.7229701280593872\n",
            "Training Accuracy per 5000 steps: 25.0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "310it [01:25,  3.65it/s]\n",
            "0it [00:00, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "The Total Accuracy for Epoch 1: 29.430763019781995\n",
            "Training Loss Epoch: 0.7366443643646855\n",
            "Training Accuracy Epoch: 29.430763019781995\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r1it [00:00,  3.86it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training Loss per 5000 steps: 0.7315409183502197\n",
            "Training Accuracy per 5000 steps: 37.5\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "310it [01:25,  3.64it/s]\n",
            "0it [00:00, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "The Total Accuracy for Epoch 2: 30.56116269681066\n",
            "Training Loss Epoch: 0.7380654402317539\n",
            "Training Accuracy Epoch: 30.56116269681066\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r1it [00:00,  3.77it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training Loss per 5000 steps: 0.7332168221473694\n",
            "Training Accuracy per 5000 steps: 25.0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "310it [01:25,  3.65it/s]\n",
            "0it [00:00, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "The Total Accuracy for Epoch 3: 30.52079127977392\n",
            "Training Loss Epoch: 0.7363466030166995\n",
            "Training Accuracy Epoch: 30.52079127977392\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r1it [00:00,  3.77it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training Loss per 5000 steps: 0.798946738243103\n",
            "Training Accuracy per 5000 steps: 12.5\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "310it [01:25,  3.64it/s]\n",
            "0it [00:00, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "The Total Accuracy for Epoch 1: 30.641905530884134\n",
            "Training Loss Epoch: 0.7346197384019052\n",
            "Training Accuracy Epoch: 30.641905530884134\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r1it [00:00,  3.72it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training Loss per 5000 steps: 0.6912280321121216\n",
            "Training Accuracy per 5000 steps: 37.5\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "310it [01:25,  3.64it/s]\n",
            "0it [00:00, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "The Total Accuracy for Epoch 2: 30.15744852644328\n",
            "Training Loss Epoch: 0.7374591427464638\n",
            "Training Accuracy Epoch: 30.15744852644328\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r1it [00:00,  3.80it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training Loss per 5000 steps: 0.7169172763824463\n",
            "Training Accuracy per 5000 steps: 25.0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "310it [01:25,  3.64it/s]\n",
            "0it [00:00, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "The Total Accuracy for Epoch 3: 30.964876867178038\n",
            "Training Loss Epoch: 0.7366842241056504\n",
            "Training Accuracy Epoch: 30.964876867178038\n",
            "Round: 2... \tAverage Loss: 0.737\n",
            "Round: 2... \tAverage Accuracy: 30.545\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r1it [00:00,  3.79it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training Loss per 5000 steps: 0.7415284514427185\n",
            "Training Accuracy per 5000 steps: 0.0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "310it [01:25,  3.64it/s]\n",
            "0it [00:00, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "The Total Accuracy for Epoch 1: 30.884134033104562\n",
            "Training Loss Epoch: 0.7358292706551091\n",
            "Training Accuracy Epoch: 30.884134033104562\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r1it [00:00,  3.73it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training Loss per 5000 steps: 0.745255172252655\n",
            "Training Accuracy per 5000 steps: 25.0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "310it [01:25,  3.64it/s]\n",
            "0it [00:00, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "The Total Accuracy for Epoch 2: 30.601534113847396\n",
            "Training Loss Epoch: 0.7364031958964563\n",
            "Training Accuracy Epoch: 30.601534113847396\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r1it [00:00,  3.72it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training Loss per 5000 steps: 0.7863683700561523\n",
            "Training Accuracy per 5000 steps: 12.5\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "310it [01:25,  3.64it/s]\n",
            "0it [00:00, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "The Total Accuracy for Epoch 3: 29.471134436818733\n",
            "Training Loss Epoch: 0.736509241596345\n",
            "Training Accuracy Epoch: 29.471134436818733\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r1it [00:00,  3.77it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training Loss per 5000 steps: 0.7248131036758423\n",
            "Training Accuracy per 5000 steps: 25.0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "310it [01:25,  3.64it/s]\n",
            "0it [00:00, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "The Total Accuracy for Epoch 1: 30.197819943480017\n",
            "Training Loss Epoch: 0.7353573560714721\n",
            "Training Accuracy Epoch: 30.197819943480017\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r1it [00:00,  3.74it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training Loss per 5000 steps: 0.7315038442611694\n",
            "Training Accuracy per 5000 steps: 25.0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "310it [01:25,  3.64it/s]\n",
            "0it [00:00, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "The Total Accuracy for Epoch 2: 31.045619701251514\n",
            "Training Loss Epoch: 0.735545160501234\n",
            "Training Accuracy Epoch: 31.045619701251514\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r1it [00:00,  3.77it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training Loss per 5000 steps: 0.734900712966919\n",
            "Training Accuracy per 5000 steps: 0.0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "310it [01:25,  3.64it/s]\n",
            "0it [00:00, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "The Total Accuracy for Epoch 3: 30.72264836495761\n",
            "Training Loss Epoch: 0.7377113138475726\n",
            "Training Accuracy Epoch: 30.72264836495761\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r1it [00:00,  3.79it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training Loss per 5000 steps: 0.6842734217643738\n",
            "Training Accuracy per 5000 steps: 50.0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "310it [01:25,  3.64it/s]\n",
            "0it [00:00, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "The Total Accuracy for Epoch 1: 30.480419862737183\n",
            "Training Loss Epoch: 0.7365362515372614\n",
            "Training Accuracy Epoch: 30.480419862737183\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r1it [00:00,  3.78it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training Loss per 5000 steps: 0.7473923563957214\n",
            "Training Accuracy per 5000 steps: 37.5\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "310it [01:25,  3.63it/s]\n",
            "0it [00:00, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "The Total Accuracy for Epoch 2: 30.56116269681066\n",
            "Training Loss Epoch: 0.7364589919967036\n",
            "Training Accuracy Epoch: 30.56116269681066\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r1it [00:00,  3.83it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training Loss per 5000 steps: 0.7601798176765442\n",
            "Training Accuracy per 5000 steps: 12.5\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "310it [01:25,  3.63it/s]\n",
            "0it [00:00, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "The Total Accuracy for Epoch 3: 30.399677028663707\n",
            "Training Loss Epoch: 0.7370324888537007\n",
            "Training Accuracy Epoch: 30.399677028663707\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r1it [00:00,  3.75it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training Loss per 5000 steps: 0.751007080078125\n",
            "Training Accuracy per 5000 steps: 25.0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "310it [01:25,  3.64it/s]\n",
            "0it [00:00, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "The Total Accuracy for Epoch 1: 30.9245054501413\n",
            "Training Loss Epoch: 0.7357388825185838\n",
            "Training Accuracy Epoch: 30.9245054501413\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r1it [00:00,  3.78it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training Loss per 5000 steps: 0.7722361087799072\n",
            "Training Accuracy per 5000 steps: 12.5\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "310it [01:25,  3.64it/s]\n",
            "0it [00:00, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "The Total Accuracy for Epoch 2: 30.52079127977392\n",
            "Training Loss Epoch: 0.73608440391479\n",
            "Training Accuracy Epoch: 30.52079127977392\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r1it [00:00,  3.80it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training Loss per 5000 steps: 0.7385095953941345\n",
            "Training Accuracy per 5000 steps: 37.5\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "310it [01:25,  3.64it/s]\n",
            "0it [00:00, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "The Total Accuracy for Epoch 3: 30.682276947920872\n",
            "Training Loss Epoch: 0.7365018419681056\n",
            "Training Accuracy Epoch: 30.682276947920872\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r1it [00:00,  3.76it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training Loss per 5000 steps: 0.7317200303077698\n",
            "Training Accuracy per 5000 steps: 25.0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "310it [01:25,  3.64it/s]\n",
            "0it [00:00, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "The Total Accuracy for Epoch 1: 29.7537343560759\n",
            "Training Loss Epoch: 0.7361692653548333\n",
            "Training Accuracy Epoch: 29.7537343560759\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r1it [00:00,  3.77it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training Loss per 5000 steps: 0.7187443375587463\n",
            "Training Accuracy per 5000 steps: 25.0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "310it [01:25,  3.64it/s]\n",
            "0it [00:00, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "The Total Accuracy for Epoch 2: 29.874848607186113\n",
            "Training Loss Epoch: 0.7370857173396695\n",
            "Training Accuracy Epoch: 29.874848607186113\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r1it [00:00,  3.67it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training Loss per 5000 steps: 0.7127504944801331\n",
            "Training Accuracy per 5000 steps: 25.0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "310it [01:25,  3.63it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "The Total Accuracy for Epoch 3: 31.53007670569237\n",
            "Training Loss Epoch: 0.7361879283382047\n",
            "Training Accuracy Epoch: 31.53007670569237\n",
            "Round: 3... \tAverage Loss: 0.737\n",
            "Round: 3... \tAverage Accuracy: 30.561\n",
            "Training Done!\n",
            "Total time taken to Train: 3835.130675792694\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oHxP3pkx5v-K",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ea375b6e-c793-40fd-90c8-3608f72a1e5e"
      },
      "source": [
        "print('This is the validation section to print the accuracy and see how it performs')\n",
        "print('Here we are leveraging on the dataloader crearted for the validation dataset, the approcah is using more of pytorch')\n",
        "\n",
        "acc = valid(bert_non_iid_trained, testing_loader, loss_function)\n",
        "print(\"Accuracy on test data = %0.2f%%\" % acc)\n",
        "\n",
        "\n",
        "d['train_acc'] = train_acc\n",
        "d['test_acc'] = acc\n",
        "\n",
        "\n",
        "with open(f'/content/drive/My Drive/Albert/Sexual_Harassment/DPFLALBERT_Harassment_eps0_5_noniid.pkl', 'wb') as file:\n",
        "  pickle.dump(d, file)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2it [00:00, 11.96it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "This is the validation section to print the accuracy and see how it performs\n",
            "Here we are leveraging on the dataloader crearted for the validation dataset, the approcah is using more of pytorch\n",
            "Validation Loss per 100 steps: 0.6576423048973083\n",
            "Validation Accuracy per 100 steps: 50.0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "310it [00:23, 13.33it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Validation Loss Epoch: 0.73312256893804\n",
            "Validation Accuracy Epoch: 31.34087237479806\n",
            "Accuracy on test data = 31.34%\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iUIsUxojzN0Q"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}